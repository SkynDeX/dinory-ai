# app/services/story/story_generator.py
import os
import logging
from typing import List, Dict, Optional, Any

logger = logging.getLogger("dinory.story")
if not logger.handlers:
    h = logging.StreamHandler()
    h.setFormatter(logging.Formatter("[STORY] %(asctime)s | %(levelname)s | %(message)s"))
    logger.addHandler(h)
logger.setLevel(logging.INFO)


class StorySearchService:
    """
    Pinecone + ì„ë² ë”© ê¸°ë°˜ ë™í™” ê²€ìƒ‰ ì„œë¹„ìŠ¤.
    - ëª¨ë“  ì™¸ë¶€ ì˜ì¡´ì„±(Pinecone, OpenAI, SBERT)ì´ ì—†ì–´ë„ ì•ˆì „ í´ë°±ìœ¼ë¡œ ë™ì‘.
    - ì—”ë“œí¬ì¸íŠ¸ì—ì„œ awaitì„ ì“¸ ìˆ˜ ìˆë„ë¡ async ë˜í¼ ì œê³µ.
    """

    def __init__(self):
        self.index = None
        self.pc = None
        self.openai_client = None
        self.embedder = None  # lazy
        self.index_name = os.getenv("PINECONE_INDEX_NAME", "story-embeddings")

        # Pinecone ì´ˆê¸°í™”
        try:
            if os.getenv("PINECONE_DISABLE", "0") == "1":
                logger.warning("Pinecone ë¹„í™œì„±í™”(PINECONE_DISABLE=1). ë”ë¯¸ë¡œ ë™ì‘")
            else:
                api_key = os.getenv("PINECONE_API_KEY")
                if not api_key:
                    logger.warning("PINECONE_API_KEY ì—†ìŒ. ë”ë¯¸ë¡œ ë™ì‘")
                else:
                    from pinecone import Pinecone  # optional import
                    self.pc = Pinecone(api_key=api_key)
                    try:
                        self.index = self.pc.Index(self.index_name)
                        logger.info(f"Pinecone ì¸ë±ìŠ¤ ì—°ê²°: {self.index_name}")
                    except Exception as e:
                        logger.error(f"Pinecone ì¸ë±ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
                        self.index = None
        except Exception as e:
            logger.error(f"Pinecone ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.pc, self.index = None, None

        # OpenAI ì„ë² ë”©(ì˜µì…˜)
        try:
            openai_key = os.getenv("OPENAI_API_KEY")
            if openai_key:
                from openai import OpenAI  # optional import
                self.openai_client = OpenAI(api_key=openai_key)
                logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸(ì„ë² ë”©) ì¤€ë¹„")
            else:
                logger.warning("OPENAI_API_KEY ì—†ìŒ. SBERT í´ë°± ì˜ˆì •")
        except Exception as e:
            logger.error(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.openai_client = None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë‚´ë¶€ ìœ í‹¸
    def _lazy_load_sbert(self) -> None:
        if self.embedder is None:
            try:
                from sentence_transformers import SentenceTransformer
                self.embedder = SentenceTransformer(
                    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
                )
                logger.info("SBERT ì„ë² ë”©ê¸° ì´ˆê¸°í™”")
            except Exception as e:
                logger.error(f"SBERT ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.embedder = None

    def create_search_query(self, emotion: Optional[str], interests: Optional[List[str]]) -> str:
        emotion_map = {
            "ê¸°ë»ìš”": "ê¸°ì¨ í–‰ë³µ ì¦ê±°ì›€ ì›ƒìŒ ì¶•í•˜ ì‹ ë‚¨ ì¢‹ì•„í•¨",
            "ìŠ¬í¼ìš”": "ìŠ¬í”” ëˆˆë¬¼ ìœ„ë¡œ ê³µê° ì•„í”” ìƒì²˜ í—¤ì–´ì§ ê·¸ë¦¬ì›€",
            "í™”ë‚˜ìš”": "í™”ë‚¨ ë¶„ë…¸ ì§œì¦ ì‹¸ì›€ ê°ˆë“± ë¯¸ì•ˆí•¨ ìš©ì„œ í™”í•´",
            "ë¬´ì„œì›Œìš”": "ë‘ë ¤ì›€ ê³µí¬ ë¬´ì„œì›€ ìš©ê¸° ê·¹ë³µ ë„ì „ ê°•í•¨",
            "ì‹ ë‚˜ìš”": "ì‹ ë‚¨ ëª¨í—˜ íƒí—˜ ì¬ë¯¸ í™œê¸° ì—ë„ˆì§€ í™œë™",
            "í”¼ê³¤í•´ìš”": "í”¼ê³¤ íœ´ì‹ í‰ì˜¨ í¸ì•ˆ ì  ì‰¼ ì—¬ìœ ",
        }
        emotion_text = emotion_map.get(emotion or "", emotion or "")
        interests_text = " ".join(interests or [])
        query = f"{emotion_text} {interests_text} ë™í™” ì´ì•¼ê¸°".strip() or "ì•„ì´ ê°ì • ê³µê° ëª¨í—˜ ìš°ì • ë™í™” ì´ì•¼ê¸°"
        logger.info(f"ê²€ìƒ‰ì–´ ìƒì„±: {query}")
        return query

    def _embed(self, text: str) -> Optional[List[float]]:
        # 1) OpenAI
        try:
            if self.openai_client:
                resp = self.openai_client.embeddings.create(
                    model="text-embedding-3-large",
                    input=text,
                )
                return resp.data[0].embedding
        except Exception as e:
            logger.error(f"OpenAI ì„ë² ë”© ì‹¤íŒ¨: {e}")

        # 2) SBERT
        try:
            self._lazy_load_sbert()
            if self.embedder:
                vec = self.embedder.encode([text])[0]
                return vec.tolist() if hasattr(vec, "tolist") else list(vec)
        except Exception as e:
            logger.error(f"SBERT ì„ë² ë”© ì‹¤íŒ¨: {e}")

        return None

    def _normalize(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ì¶œë ¥ í‘œì¤€í™”:
        {
            storyId, title, matchingScore, metadata
        }
        """
        normed = []
        for it in items:
            normed.append({
                "storyId": it.get("story_id") or it.get("id") or it.get("storyId"),
                "title": it.get("title") or it.get("metadata", {}).get("title", "ì œëª© ì—†ìŒ"),
                "matchingScore": int(it.get("matching_score") or it.get("score") or 0),
                "metadata": it.get("metadata") or {},
            })
        return normed

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í¼ë¸”ë¦­ API
    def search_stories(
        self,
        emotion: Optional[str],
        interests: Optional[List[str]],
        top_k: int = 5,
    ) -> List[Dict[str, Any]]:
        """
        Pineconeê°€ ì—†ìœ¼ë©´ ë”ë¯¸. ìˆìœ¼ë©´ ì„ë² ë”© ì¿¼ë¦¬.
        ë°˜í™˜ì€ _normalize í˜•ì‹ ì „ì œ.
        """
        if not self.index:
            logger.warning("Pinecone ì¸ë±ìŠ¤ ë¯¸ì—°ê²° â†’ ë”ë¯¸ ë°˜í™˜")
            return self._normalize(self._get_dummy_stories(emotion, interests or [], top_k))

        query_text = self.create_search_query(emotion, interests)
        vec = self._embed(query_text)
        if vec is None:
            logger.error("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ â†’ ë”ë¯¸ ë°˜í™˜")
            return self._normalize(self._get_dummy_stories(emotion, interests or [], top_k))

        try:
            # results = self.index.query(vector=vec, top_k=top_k, include_metadata=True) # ê¸°ì¡´ ì½”ë“œ
            # [2025-10-29 ê¹€ê´‘í˜„]ì¤‘ë³µì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ top_kë³´ë‹¤ ë”ë§ì€ ë™í™” ì°¾ê¸°(ìˆ˜ì •ì½”ë“œ)
            results = self.index.query(vector=vec, top_k=top_k * 2, include_metadata=True)
            matches = getattr(results, "matches", None) or getattr(results, "data", None) or results.get("matches", [])  # type: ignore[attr-defined]
            
            stories: List[Dict[str, Any]] = []
            seen_ids = set()    # [2025-10-29 ê¹€ê´‘í˜„] ID ì¤‘ë³µ ì²´í¬ìš©
            seen_titles = set()  # [2025-11-12 ì¶”ê°€] ì œëª© ì¤‘ë³µ ì²´í¬ìš©

            for m in matches:
                mid = getattr(m, "id", None) or (m.get("id") if isinstance(m, dict) else None)
                score = getattr(m, "score", None) or (m.get("score") if isinstance(m, dict) else 0.0)
                meta = getattr(m, "metadata", None) or (m.get("metadata") if isinstance(m, dict) else {}) or {}
                title = meta.get("title", "ì œëª© ì—†ìŒ")

                # [2025-11-12 ìˆ˜ì •] IDì™€ ì œëª© ë‘˜ ë‹¤ ì¤‘ë³µ ì²´í¬
                if mid in seen_ids or title in seen_titles:
                    continue

                seen_ids.add(mid)
                seen_titles.add(title)

                stories.append(
                    {
                        "story_id": mid,
                        "title": title,
                        "matching_score": int(float(score) * 100),
                        "metadata": meta,
                    }
                )

                # # [2025-10-29 ê¹€ê´‘í˜„] ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ëª¨ì´ë©´ ì¤‘ë‹¨
                if len(stories) >= top_k:
                    break

            logger.info(f"Pinecone ê²€ìƒ‰ ê²°ê³¼ (ID/ì œëª© ì¤‘ë³µ ì œê±° ì „/í›„): {len(matches)}/{len(stories)}ê°œ")
            return self._normalize(stories)
        
        except Exception as e:
            logger.error(f"Pinecone ê²€ìƒ‰ ì˜¤ë¥˜ â†’ ë”ë¯¸ ë°˜í™˜: {e}")
            return self._normalize(self._get_dummy_stories(emotion, interests or [], top_k))

    async def recommend_stories_async(
        self,
        emotion: Optional[str],
        interests: Optional[List[str]],
        child_id: Optional[int],
        limit: int = 5,
    ) -> List[Dict[str, Any]]:
        """
        ì—”ë“œí¬ì¸íŠ¸ì—ì„œ await ê°€ëŠ¥í•˜ë„ë¡ ì œê³µí•˜ëŠ” async ë˜í¼.

        [2025-11-12 ê¹€ê´‘í˜„] AI ì¤„ê±°ë¦¬ ìƒì„± ê¸°ëŠ¥ ì¶”ê°€
        - Pinecone ê²€ìƒ‰ í›„ ê° ë™í™” ì œëª©ìœ¼ë¡œ AIê°€ ì¤„ê±°ë¦¬ ìƒì„±
        - metadata["ai_summary"]ì— ì €ì¥í•˜ì—¬ ë°±ì—”ë“œë¡œ ì „ë‹¬

        [2025-11-12 ìˆ˜ì •] ì´ë¯¸ ì½ì€ ë™í™” ì œì™¸
        - child_idë¡œ ì™„ë£Œí•œ ë™í™” ëª©ë¡ ì¡°íšŒ
        - ì¶”ì²œ ê²°ê³¼ì—ì„œ ì¤‘ë³µ ì œê±°
        """
        import httpx
        import os

        # [2025-11-12 ì¶”ê°€] ì´ë¯¸ ì½ì€ ë™í™” ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        read_story_ids = set()
        if child_id:
            try:
                spring_api_url = os.getenv("SPRING_API_URL", "http://localhost:8090/api")
                async with httpx.AsyncClient(timeout=5.0) as client:
                    response = await client.get(
                        f"{spring_api_url}/story/completions/child/{child_id}",
                        params={"limit": 100}
                    )
                    if response.status_code == 200:
                        completions = response.json()
                        read_story_ids = {str(c.get("storyId")) for c in completions if c.get("storyId")}
                        logger.info(f"âœ… ì•„ì´ {child_id}ì˜ ì½ì€ ë™í™” {len(read_story_ids)}ê°œ ì œì™¸")
                    else:
                        logger.warning(f"âš ï¸ ì½ì€ ë™í™” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.status_code}")
            except Exception as e:
                logger.warning(f"âš ï¸ ì½ì€ ë™í™” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # ê¸°ì¡´ ë™ê¸° ê²€ìƒ‰ (ë” ë§ì´ ê°€ì ¸ì™€ì„œ ì¤‘ë³µ ì œê±° í›„ limit ë§ì¶”ê¸°)
        stories = self.search_stories(emotion, interests, top_k=limit * 3)

        # [2025-11-12 ì¶”ê°€] ì´ë¯¸ ì½ì€ ë™í™” ì œì™¸
        filtered_stories = [
            story for story in stories
            if story.get("storyId") not in read_story_ids
        ][:limit]  # í•„í„°ë§ í›„ limitë§Œí¼ë§Œ

        logger.info(f"ğŸ“š ì „ì²´ ì¶”ì²œ: {len(stories)}ê°œ â†’ ì¤‘ë³µ ì œê±° í›„: {len(filtered_stories)}ê°œ")

        # ê° ë™í™”ì— AI ì¤„ê±°ë¦¬ ì¶”ê°€ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ ê°œì„ )
        from app.services.llm.openai_service import OpenAIService
        import asyncio

        openai_service = OpenAIService()

        async def add_ai_summary(story: Dict[str, Any]) -> Dict[str, Any]:
            """ê° ë™í™”ì— AI ìƒì„± ì¤„ê±°ë¦¬ ì¶”ê°€"""
            title = story.get("title", "ì œëª© ì—†ìŒ")
            metadata = story.get("metadata", {})

            try:
                # AIë¡œ ì¤„ê±°ë¦¬ ìƒì„±
                ai_summary = await openai_service.generate_story_summary(title)
                metadata["ai_summary"] = ai_summary
                logger.info(f"âœ… AI ì¤„ê±°ë¦¬ ìƒì„±: {title[:20]}... â†’ {ai_summary[:30]}...")
            except Exception as e:
                logger.warning(f"âš ï¸ AI ì¤„ê±°ë¦¬ ìƒì„± ì‹¤íŒ¨: {title}, {str(e)}")
                # ì‹¤íŒ¨ ì‹œ plotSummaryText ì‚¬ìš©í•˜ê±°ë‚˜ ê¸°ë³¸ ë¬¸êµ¬
                fallback = metadata.get("plotSummaryText") or f"{title}ì˜ ì´ì•¼ê¸°ì˜ˆìš”."
                metadata["ai_summary"] = fallback

            story["metadata"] = metadata
            return story

        # ëª¨ë“  ë™í™”ì— ëŒ€í•´ ë³‘ë ¬ë¡œ AI ì¤„ê±°ë¦¬ ìƒì„± (í•„í„°ë§ëœ ë™í™”ë§Œ)
        try:
            enriched_stories = await asyncio.gather(*[add_ai_summary(s) for s in filtered_stories])
            logger.info(f"âœ… {len(enriched_stories)}ê°œ ë™í™”ì— AI ì¤„ê±°ë¦¬ ì¶”ê°€ ì™„ë£Œ")
            return enriched_stories
        except Exception as e:
            logger.error(f"âŒ AI ì¤„ê±°ë¦¬ ì¼ê´„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨í•´ë„ í•„í„°ë§ëœ stories ë°˜í™˜
            return filtered_stories

    def get_story_by_id(self, story_id: str) -> Optional[Dict[str, Any]]:
        if not self.index:
            logger.warning("Pinecone ë¯¸ì—°ê²° â†’ None")
            return None
        try:
            result = self.index.fetch(ids=[story_id])
            vectors = getattr(result, "vectors", None) or result.get("vectors", {})
            if story_id in vectors:
                meta = vectors[story_id].get("metadata", {}) or {}
                return {"storyId": story_id, "title": meta.get("title", "ì œëª© ì—†ìŒ"), "metadata": meta}
            logger.info(f"Pineconeì— ì—†ìŒ: {story_id}")
            return None
        except Exception as e:
            logger.error(f"{story_id} ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë”ë¯¸ ë°ì´í„°
    def _get_dummy_stories(self, emotion: Optional[str], interests: List[str], top_k: int) -> List[Dict[str, Any]]:
        dummy = [
            {
                "story_id": "new_sibling",
                "title": "ìƒˆ ë™ìƒê³¼ì˜ í•˜ë£¨",
                "matching_score": 96,
                "metadata": {"classification": "ê°€ì¡±", "readAge": "ìœ ì•„", "plotSummaryText": "ìƒˆë¡œìš´ ê°€ì¡±ì„ ë§ì´í•˜ë©° ë°°ìš°ëŠ” ê³µê°"},
            },
            {
                "story_id": "brave_little_star",
                "title": "ì‘ì€ ë³„ì˜ ìš©ê¸°",
                "matching_score": 93,
                "metadata": {"classification": "ìš©ê¸°", "readAge": "ìœ ì•„", "plotSummaryText": "ë‘ë ¤ì›€ì„ ì´ê²¨ë‚´ëŠ” ëª¨í—˜"},
            },
            {
                "story_id": "forest_friends",
                "title": "ìˆ²ì† ì¹œêµ¬ë“¤",
                "matching_score": 89,
                "metadata": {"classification": "ìš°ì •", "readAge": "ìœ ì•„", "plotSummaryText": "ì„œë¡œ ë•ëŠ” ì¹œêµ¬ë“¤ì˜ ì´ì•¼ê¸°"},
            },
            {
                "story_id": "angry_rabbit",
                "title": "í™”ë‚œ í† ë¼ì˜ í•˜ë£¨",
                "matching_score": 85,
                "metadata": {"classification": "ê°ì •ì¡°ì ˆ", "readAge": "ìœ ì•„", "plotSummaryText": "í™”ë¥¼ ë‹¤ë£¨ëŠ” ë²• ë°°ìš°ê¸°"},
            },
            {
                "story_id": "magic_adventure",
                "title": "ë§ˆë²•ì˜ ëª¨í—˜",
                "matching_score": 82,
                "metadata": {"classification": "ëª¨í—˜", "readAge": "ìœ ì•„", "plotSummaryText": "ì‘ì€ ë§ˆë²•ì‚¬ì˜ ì„±ì¥ê¸°"},
            },
        ]
        logger.info(f"ë”ë¯¸ {top_k}ê°œ ë°˜í™˜")
        return dummy[:top_k]
