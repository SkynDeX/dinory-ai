"""
Enhanced Chatbot Service with RAG Memory
ê¸°ì¡´ chatbot_service.pyë¥¼ í™•ì¥í•˜ì—¬ RAG ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ì¶”ê°€
"""

import os
from typing import Optional, Dict, Any, List
from openai import AsyncOpenAI
from app.services.chat.memory_service import MemoryService


class ChatbotServiceWithRAG:
    """
    RAG ë©”ëª¨ë¦¬ê°€ í†µí•©ëœ ì±—ë´‡ ì„œë¹„ìŠ¤

    ê¸°ì¡´ ê¸°ëŠ¥:
    - ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    - ë™í™” ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŒ€í™”

    ìƒˆë¡œìš´ RAG ê¸°ëŠ¥:
    - ê³¼ê±° ëª¨ë“  ëŒ€í™” ê¸°ì–µ
    - ì™„ë£Œí•œ ë™í™” ê¸°ë¡ ì°¸ì¡°
    - ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ìë™ ê²€ìƒ‰
    """

    def __init__(self, use_pinecone: bool = False):
        """
        Args:
            use_pinecone: Trueë©´ Pinecone ë²¡í„° ê²€ìƒ‰ ì‚¬ìš©, Falseë©´ MySQLë§Œ ì‚¬ìš©
        """
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-4o-mini"
        self.system_prompt = """
ë‹¹ì‹ ì€ ì•„ì´ë“¤ì„ ìœ„í•œ ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ AI ì¹œêµ¬ 'ë””ë…¸'ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¼ì£¼ì„¸ìš”:

1. í•­ìƒ ë°˜ë§ì„ ì‚¬ìš©í•˜ê³ , ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš” (ì˜ˆ: "~ì•¼", "~ë‹ˆ?", "~ì–´")
2. ì•„ì´ì˜ ê°ì •ì„ ì´í•´í•˜ê³  ê³µê°í•´ì£¼ì„¸ìš”
3. ê¸ì •ì ì´ê³  êµìœ¡ì ì¸ ë‚´ìš©ì„ ì „ë‹¬í•˜ì„¸ìš”
4. ë³µì¡í•œ ê°œë…ì€ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”
5. ì•„ì´ê°€ ê¶ê¸ˆí•´í•˜ëŠ” ê²ƒì— ëŒ€í•´ ì ê·¹ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
6. ì•ˆì „í•˜ê³  ê±´ì „í•œ ëŒ€í™”ë¥¼ ìœ ì§€í•˜ì„¸ìš”
7. ì§§ê³  ê°„ê²°í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš” (1-3ë¬¸ì¥)
"""
        # ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (í˜„ì¬ ì„¸ì…˜ ë‚´ ë©”ëª¨ë¦¬)
        self.conversation_history = {}
        # ì„¸ì…˜ë³„ ë™í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        self.story_context = {}

        # RAG ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ (ì¥ê¸° ë©”ëª¨ë¦¬)
        self.memory_service = MemoryService(use_pinecone=use_pinecone)
        self.use_memory = True  # RAG ê¸°ëŠ¥ on/off

    async def generate_response(
        self,
        message: str,
        session_id: int,
        child_id: Optional[int] = None
    ) -> str:
        """
        ì•„ì´ì˜ ë©”ì‹œì§€ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„± (RAG ë©”ëª¨ë¦¬ í†µí•©)
        """
        print(f"\n=== generate_response with RAG ===")
        print(f"session_id: {session_id}, child_id: {child_id}")
        print(f"message: {message}")

        # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
        if session_id not in self.conversation_history:
            self.conversation_history[session_id] = []

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        self.conversation_history[session_id].append({
            "role": "user",
            "content": message
        })

        # OpenAI API í˜¸ì¶œ
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°ë³¸ ë˜ëŠ” ë™í™” ì»¨í…ìŠ¤íŠ¸)
            system_prompt = await self._build_system_prompt(
                session_id,
                message,
                child_id
            )

            messages = [
                {"role": "system", "content": system_prompt}
            ] + [{"role": m["role"], "content": m["content"]}
                 for m in self.conversation_history[session_id]]

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=200
            )

            ai_response = response.choices[0].message.content

            # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history[session_id].append({
                "role": "assistant",
                "content": ai_response
            })

            return ai_response

        except Exception as e:
            print(f"Error generating response: {e}")
            return "ì£„ì†¡í•´ìš”, ì ì‹œ í›„ì— ë‹¤ì‹œ ì´ì•¼ê¸°í•´ìš”!"

    async def _build_system_prompt(
        self,
        session_id: int,
        current_message: str,
        child_id: Optional[int]
    ) -> str:
        """
        RAG ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ê°€ í’ë¶€í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        base_prompt = self.system_prompt

        # 1. ë™í™” ì»¨í…ìŠ¤íŠ¸ (í˜„ì¬ ì„¸ì…˜ì— ë™í™” ì •ë³´ê°€ ìˆìœ¼ë©´)
        story_context_text = ""
        if session_id in self.story_context:
            story_info = self.story_context[session_id]
            ability_details = self._format_ability_details(story_info["abilities"])

            story_context_text = f"""
**ë™í™” ì •ë³´:**
- ë™í™” ì œëª©: '{story_info["story_title"]}'
- íšë“í•œ ëŠ¥ë ¥ì¹˜:
{ability_details}

**ì¤‘ìš” ì§€ì¹¨:**
- ì•„ì´ê°€ "ëŠ¥ë ¥ì¹˜", "ëŠ¥ë ¥", "ìŠ¤íƒ¯", "ì–»ì€ ê²ƒ" ë“±ì„ ë¬¼ì–´ë³´ë©´ ìœ„ ëŠ¥ë ¥ì¹˜ ì •ë³´ë¥¼ ì •í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”
- ë™í™” ë‚´ìš©ê³¼ ì—°ê´€ì§€ì–´ ëŒ€í™”í•˜ì„¸ìš”
"""

        # 2. RAG ë©”ëª¨ë¦¬ (ê³¼ê±° ëŒ€í™” ë° ë™í™” ê¸°ë¡)
        memory_context_text = ""
        if self.use_memory and child_id:
            memory_context = await self.memory_service.get_relevant_context(
                current_message=current_message,
                child_id=child_id,
                session_id=session_id
            )

            if memory_context["summary"]:
                memory_context_text = f"""
**ì•„ì´ì˜ ê¸°ì–µ (ê³¼ê±° ê¸°ë¡):**
{memory_context["summary"]}

**ëŒ€í™” ì§€ì¹¨:**
- ì•„ì´ê°€ ê³¼ê±°ì— ì½ì€ ë™í™”ë‚˜ ì´ì „ ëŒ€í™”ë¥¼ ë¬¼ì–´ë³´ë©´ ìœ„ ê¸°ë¡ì„ ì°¸ê³ í•˜ì„¸ìš”
- "ì§€ë‚œë²ˆì— ë­ ì½ì—ˆì–´?", "ì „ì— ë¬´ìŠ¨ ì–˜ê¸°í–ˆì§€?" ê°™ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”
- ìì—°ìŠ¤ëŸ½ê²Œ ê³¼ê±° ê²½í—˜ì„ ì–¸ê¸‰í•˜ë©° ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”
"""

        # 3. í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±
        enhanced_prompt = f"""
{base_prompt}

{story_context_text}

{memory_context_text}

**ëŒ€í™” ê°€ì´ë“œë¼ì¸:**
1. ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš” (ì˜ˆ: "~ì•¼", "~ë‹ˆ?", "~ì–´")
2. ì•„ì´ì˜ ê°ì •ì„ ì´í•´í•˜ê³  ê²©ë ¤í•´ì£¼ì„¸ìš”
3. ì§§ê³  ê°„ê²°í•˜ê²Œ 1-2ë¬¸ì¥ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
4. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš” (ğŸ˜Š, ğŸ’™, âœ¨)
5. ì•„ì´ì˜ ìƒê°ê³¼ ê°ì •ì„ ë” ì´ëŒì–´ë‚´ëŠ” ì§ˆë¬¸ì„ í•˜ì„¸ìš”
""".strip()

        return enhanced_prompt

    async def generate_first_message_from_story(
        self,
        session_id: int,
        child_name: str,
        story_title: str,
        story_id: str,
        abilities: Dict[str, int],
        choices: List[Dict[str, Any]],
        total_time: Optional[int] = None
    ) -> str:
        """
        ë™í™” ì™„ë£Œ í›„ ì²« ëŒ€í™” ë©”ì‹œì§€ ìƒì„± (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
        """
        print(f"\n=== generate_first_message_from_story ===")

        # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        if session_id not in self.conversation_history:
            self.conversation_history[session_id] = []

        # ë™í™” ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        self.story_context[session_id] = {
            "story_title": story_title,
            "story_id": story_id,
            "abilities": abilities,
            "choices": choices
        }

        # ëŠ¥ë ¥ì¹˜ ë¶„ì„
        ability_details = self._format_ability_details(abilities)

        # ë™í™”ë³„ ë§ì¶¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        story_aware_prompt = f"""
ë‹¹ì‹ ì€ ì•„ì´ë“¤ì„ ìœ„í•œ ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ AI ì¹œêµ¬ 'ë””ë…¸'ì…ë‹ˆë‹¤.

ì•„ì´ '{child_name}'ê°€ ë°©ê¸ˆ '{story_title}' ë™í™”ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.

**íšë“í•œ ëŠ¥ë ¥ì¹˜:**
{ability_details}

**ì¤‘ìš” ì§€ì¹¨:**
- ì•„ì´ê°€ "ëŠ¥ë ¥ì¹˜", "ëŠ¥ë ¥", "ìŠ¤íƒ¯", "ì–»ì€ ê²ƒ" ë“±ì„ ë¬¼ì–´ë³´ë©´ ìœ„ ëŠ¥ë ¥ì¹˜ ì •ë³´ë¥¼ ì •í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”
- ë™í™” ë‚´ìš©ê³¼ ì—°ê´€ì§€ì–´ ëŒ€í™”í•˜ì„¸ìš”

**ëŒ€í™” ê°€ì´ë“œë¼ì¸:**
1. ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš” (ì˜ˆ: "{child_name}ì•¼", "ì–´ë• ì–´?", "ì¬ë¯¸ìˆì—ˆë‹ˆ?")
2. ë™í™” ë‚´ìš©ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¼ì–´ë³´ì„¸ìš”
3. ì•„ì´ì˜ ê°ì •ê³¼ ìƒê°ì„ ëŒì–´ë‚´ëŠ” ì§ˆë¬¸ì„ í•˜ì„¸ìš”
4. ê³µê°í•˜ê³  ê²©ë ¤í•˜ëŠ” íƒœë„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”
5. ì§§ê³  ê°„ê²°í•˜ê²Œ 1-2ë¬¸ì¥ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
6. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: ğŸ˜Š, ğŸ’™, âœ¨)

**ì²« ë©”ì‹œì§€ ì‘ì„± ì‹œ:**
- ë™í™”ê°€ ì–´ë• ëŠ”ì§€ ë¨¼ì € ë¬¼ì–´ë³´ì„¸ìš”
- ë™í™” ì œëª©ì„ ì–¸ê¸‰í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ½ê²Œ "ë™í™”"ë¼ê³  í‘œí˜„í•˜ì„¸ìš”
- ì•„ì´ì˜ ê¸°ë¶„ì´ë‚˜ ìƒê°ì„ ë¬¼ì–´ë³´ì„¸ìš”
"""

        try:
            messages = [
                {"role": "system", "content": story_aware_prompt},
                {"role": "user", "content": "ë™í™”ë¥¼ ë‹¤ ë´¤ì–´ìš”"}
            ]

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.8,
                max_tokens=150
            )

            first_message = response.choices[0].message.content

            # AIì˜ ì²« ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history[session_id].append({
                "role": "assistant",
                "content": first_message,
                "context": "story_completion"
            })

            return first_message

        except Exception as e:
            print(f"Error generating first message from story: {e}")
            return f"{child_name}ì•¼, ë™í™” ì–´ë• ì–´? ì¬ë¯¸ìˆì—ˆë‹ˆ? ì§€ê¸ˆ ê¸°ë¶„ì´ ì–´ë•Œ? ğŸ˜Š"

    def clear_history(self, session_id: int):
        """íŠ¹ì • ì„¸ì…˜ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì‚­ì œ"""
        if session_id in self.conversation_history:
            del self.conversation_history[session_id]

    def get_history(self, session_id: int):
        """íŠ¹ì • ì„¸ì…˜ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return self.conversation_history.get(session_id, [])

    def _format_ability_details(self, abilities: Dict[str, int]) -> str:
        """ëŠ¥ë ¥ì¹˜ë¥¼ ìƒì„¸í•˜ê²Œ í¬ë§·íŒ…"""
        ability_names = {
            "courage": "ìš©ê¸°",
            "empathy": "ê³µê°",
            "creativity": "ì°½ì˜ì„±",
            "responsibility": "ì±…ì„ê°",
            "friendship": "ìš°ì •"
        }

        details = []
        for key, value in abilities.items():
            korean_name = ability_names.get(key, key)
            if value > 0:
                details.append(f"  * {korean_name}: +{value}ì ")
            else:
                details.append(f"  * {korean_name}: 0ì ")

        return "\n".join(details) if details else "  * ëŠ¥ë ¥ì¹˜ ì •ë³´ ì—†ìŒ"

    async def generate_choices(
        self,
        session_id: int,
        child_id: Optional[int] = None,
        last_message: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        [2025-11-04 ê¹€ë¯¼ì¤‘ ì¶”ê°€] AI ê¸°ë°˜ ë™ì  ì„ íƒì§€ ìƒì„±
        ëŒ€í™” ë§¥ë½ì— ë§ëŠ” ì„ íƒì§€ë¥¼ ìƒì„±í•˜ê³ , Dinoì˜ ê°ì •ë„ íŒë‹¨í•©ë‹ˆë‹¤.
        """
        print(f"\n=== generate_choices í˜¸ì¶œ (RAG) ===")
        print(f"session_id: {session_id}, last_message: {last_message}")

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        history = self.conversation_history.get(session_id, [])

        # ìµœê·¼ ëŒ€í™” ë§¥ë½ êµ¬ì„± (ë§ˆì§€ë§‰ 3ê°œ ë©”ì‹œì§€)
        recent_context = history[-3:] if len(history) > 3 else history
        context_text = "\n".join([
            f"{'ì‚¬ìš©ì' if msg['role'] == 'user' else 'AI'}: {msg['content']}"
            for msg in recent_context
        ])

        try:
            # AIì—ê²Œ ì„ íƒì§€ ìƒì„± ìš”ì²­
            prompt = f"""
ëŒ€í™” ë§¥ë½:
{context_text}

ìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
1. ì•„ì´ê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì„ íƒì§€ 2-3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”
2. ê° ì„ íƒì§€ëŠ” ì§§ê³  ê°„ë‹¨í•´ì•¼ í•©ë‹ˆë‹¤ (5-10ì)
3. ì„ íƒì§€ëŠ” ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ë° ë„ì›€ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
4. í˜„ì¬ ì•„ì´ì˜ ê°ì •ì„ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”: happy, sad, angry, neutral

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "choices": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3"],
    "emotion": "ê°ì •"
}}
"""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì•„ì´ì™€ì˜ ëŒ€í™”ë¥¼ ë•ëŠ” AIì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ]

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=200,
                response_format={"type": "json_object"}
            )

            import json
            result = json.loads(response.choices[0].message.content)

            print(f"ìƒì„±ëœ ì„ íƒì§€ (RAG): {result}")

            return {
                "choices": result.get("choices", ["ë” ì•Œë ¤ì¤˜", "ë‹¤ë¥¸ ì´ì•¼ê¸°"]),
                "emotion": result.get("emotion", "neutral")
            }

        except Exception as e:
            print(f"Error generating choices (RAG): {e}")
            # í´ë°±: ê¸°ë³¸ ì„ íƒì§€ ë°˜í™˜
            return {
                "choices": ["ë” ì•Œë ¤ì¤˜", "ë‹¤ë¥¸ ì´ì•¼ê¸°"],
                "emotion": "neutral"
            }
